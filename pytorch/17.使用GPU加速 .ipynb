{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "17.使用GPU加速.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRHSQg8737r5",
        "colab_type": "text"
      },
      "source": [
        "### CUDA\n",
        "在pytorch中，以下数据结构分为CPU和GPU两种：\n",
        "1. Tensor\n",
        "2. Variable（pytorch1.0后已经弃用）\n",
        "3. Parameter\n",
        "4. nn.Module（包括常用的layer，loss function， 以及Sequential）  \n",
        "\n",
        "他们共性是都有一个`.cuda`方法，调用此方法即可将其转为对应的GPU对象。注意：\n",
        "1. tensor.cuda和vairable.cuda会返回一个新对象\n",
        "2. 这个新对象的数据已经转移至GPU，而之前的tensor/variable还在原来的设备上\n",
        "3. module.cuda会将所有的数据都迁移至GPU，并返回自己。所以`module=module.cuda() `和`module.cuda()`是相同的效果\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omppWmcd4Jsh",
        "colab_type": "text"
      },
      "source": [
        "#### 首先检测CUDA是否可用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n9Mole94IeF",
        "colab_type": "code",
        "outputId": "d3bc13f4-c7ca-446f-e518-25930d937e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch as t\n",
        "t.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZwkf6R9x6yV",
        "colab_type": "code",
        "outputId": "a8407b48-75b9-4040-83cc-0fc63ab7aaf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch as t\n",
        "a = t.Tensor(3, 4)\n",
        "# 返回一个新的tensor，保存在第1块GPU上，但是原来的tensor并没有改变\n",
        "a.cuda(0)\n",
        "a.is_cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJxQYeGG4kZe",
        "colab_type": "code",
        "outputId": "0b3cb034-2764-4493-a132-1e667e5feec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 如果不指定cuda参数，那么默认存在第1块GPU上\n",
        "a = a.cuda()\n",
        "a.is_cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWxEpqUF41yQ",
        "colab_type": "code",
        "outputId": "7566ed60-baae-40b6-c522-8c220d3f9118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from torch import nn\n",
        "module = nn.Linear(3,4)\n",
        "# 对于模型来说，调用cuda方法会将自己的数据全部转移至GPU上\n",
        "module.cuda()\n",
        "module.weight.is_cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PK85Ntm5V32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VeryBigModule(nn.Module):\n",
        "  def __init__(self):\n",
        "    super()\n",
        "    self.GiantParameter1 = nn.Parameter(t.randn(10000,20000)).cuda(0)\n",
        "    self.GiantParameter2 = nn.Parameter(t.randn(20000,1000000)).cuda(1)\n",
        "  def forward(self, x):\n",
        "    x = self.GiantParameter1.mm(x.cuda(0))\n",
        "    x = self.GiantParameter2.mm(x.cuda(1))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vINWyFvg6hlP",
        "colab_type": "text"
      },
      "source": [
        "上面这部分，两个Parameter所占内存非常大，如果将这两个Parameter放到同一块GPU上运算，几乎会将Parameter占满，此时可以将其放在不同的GPU上运算。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTAQ48tf6-jb",
        "colab_type": "text"
      },
      "source": [
        "**注意**：大部分的损失函数也都属于`nn.Module`，但在使用GPU时，如果我们忘记调用cuda方法，一般不会报错，但是**在某些情况下，会出现问题，所以应该记得要调用cuda方法**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChVPfn9u6la5",
        "colab_type": "code",
        "outputId": "d1f692e6-924d-4987-d614-abd8b52e2464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 交叉熵损失函数，带权重\n",
        "criterion = nn.CrossEntropyLoss(weight = t.Tensor([1,3]))\n",
        "input = t.randn(4,2, requires_grad=True).cuda()\n",
        "\n",
        "# requires_grad_可以在原Tensor上直接修改，避免拷贝\n",
        "target = t.Tensor([1,0,0,1]).long().cuda()\n",
        "\n",
        "# loss = criterion(input, target)\n",
        "\n",
        "criterion.cuda()\n",
        "loss = criterion(input, target)\n",
        "criterion._buffers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([1., 3.], device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALCH8f1m8xgU",
        "colab_type": "text"
      },
      "source": [
        "`loss = criterion(input, target)`这行会报错是因为`criterion`中有一个weight参数，并不在GPU上"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tDyHS8e_L_2",
        "colab_type": "text"
      },
      "source": [
        "除了调用对象`.cuda`方法，还可以**使用`torch.cuda.device`指定默认使用哪一块GPU**，或者使用**`torch.set_default_tensor_type`使程序默认使用GPU**，这样就不需要手动调用cuda切换GPU和CPU了"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4gEl1rO_LDh",
        "colab_type": "code",
        "outputId": "980a4cd6-41e8-46e3-d18f-d231707c9869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "x = t.cuda.FloatTensor(2,3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00, 1.8750e+00, 1.4013e-45],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI0ncSu4_mgc",
        "colab_type": "code",
        "outputId": "0c20f856-4416-4fdc-d59f-7e38f44c546a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 指定默认使用GPU 0\n",
        "with t.cuda.device(0):\n",
        "  a = t.cuda.FloatTensor(2,3)\n",
        "  b = t.cuda.FloatTensor(2,3)\n",
        "  \n",
        "  c = a +b\n",
        "  print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.8750,  1.9844, -0.0196],\n",
            "        [ 2.1439, -1.4802, -1.9669]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v_YgYku_3QR",
        "colab_type": "code",
        "outputId": "fd60ad01-7703-41a7-86d7-cefb0a4c1e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 指定默认tensor类型为GPU上的FloatTensor\n",
        "t.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "a = t.ones(2,3)\n",
        "print(a.is_cuda, a.get_device())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}